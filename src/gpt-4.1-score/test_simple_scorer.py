#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent))

from simple_mmlu_scorer import SimpleMMLUScorer

def test_single_question():
    """å˜ä¸€å•é¡Œã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª å˜ä¸€å•é¡Œãƒ†ã‚¹ãƒˆ")
    
    # ãƒ†ã‚¹ãƒˆç”¨å•é¡Œ
    question = "ã‚¹ã‚¿ãƒƒã‚¯ã¯åˆ¥åä½•ã¨å‘¼ã°ã‚Œã¾ã™ã‹ï¼Ÿ"
    options = [
        "FIFO memory",
        "Flash memory", 
        "LIFO memory",
        "LILO memory"
    ]
    correct_answer = "C"
    
    try:
        scorer = SimpleMMLUScorer()
        
        print(f"å•é¡Œ: {question}")
        print("é¸æŠè‚¢:")
        for i, option in enumerate(options):
            letter = chr(ord('A') + i)
            print(f"  {letter}) {option}")
        print(f"æ­£è§£: {correct_answer}")
        print()
        
        # å›ç­”å–å¾—
        result = scorer.get_answer(question, options)
        
        print("çµæœ:")
        print(f"  äºˆæ¸¬å›ç­”: {result['predicted_answer']}")
        print(f"  æ­£è§£: {correct_answer}")
        print(f"  æ­£ç­”: {'âœ…' if result['predicted_answer'] == correct_answer else 'âŒ'}")
        print(f"  å¿œç­”æ™‚é–“: {result['response_time']:.2f}ç§’")
        print(f"  æˆåŠŸ: {'âœ…' if result['success'] else 'âŒ'}")
        
        if not result['success']:
            print(f"  ã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown')}")
        
        if 'raw_response' in result:
            print(f"  ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: {result['raw_response']}")
        
        return result['success']
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_csv_loading():
    """CSVèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª CSVèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ")
    
    csv_path = project_root / "data" / "mmlu_pro_100.csv"
    
    if not csv_path.exists():
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return False
    
    try:
        scorer = SimpleMMLUScorer()
        problems = scorer.load_csv_data(str(csv_path))
        
        print(f"âœ… {len(problems)}å•ã‚’èª­ã¿è¾¼ã¿æˆåŠŸ")
        
        # æœ€åˆã®å•é¡Œã‚’è¡¨ç¤º
        if problems:
            first_problem = problems[0]
            print(f"\næœ€åˆã®å•é¡Œä¾‹:")
            print(f"  ID: {first_problem['question_id']}")
            print(f"  å•é¡Œ: {first_problem['question'][:100]}...")
            print(f"  é¸æŠè‚¢æ•°: {len(first_problem['options'])}")
            print(f"  æ­£è§£: {first_problem['correct_answer']}")
        
        return True
    
    except Exception as e:
        print(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_few_questions():
    """å°‘æ•°å•é¡Œã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª å°‘æ•°å•é¡Œãƒ†ã‚¹ãƒˆï¼ˆ3å•ï¼‰")
    
    csv_path = project_root / "data" / "mmlu_pro_100.csv"
    
    if not csv_path.exists():
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return False
    
    try:
        scorer = SimpleMMLUScorer()
        problems = scorer.load_csv_data(str(csv_path))
        
        # æœ€åˆã®3å•ã‚’ãƒ†ã‚¹ãƒˆ
        test_problems = problems[:3]
        results = []
        correct_count = 0
        
        for i, problem in enumerate(test_problems, 1):
            print(f"\n[{i}/3] å•é¡Œ {problem['question_id']}")
            print(f"å•é¡Œ: {problem['question'][:80]}...")
            
            answer_result = scorer.get_answer(problem['question'], problem['options'])
            is_correct = answer_result['predicted_answer'] == problem['correct_answer']
            
            if is_correct:
                correct_count += 1
            
            status = "âœ…" if is_correct else "âŒ"
            print(f"çµæœ: {status} äºˆæ¸¬={answer_result['predicted_answer']}, æ­£è§£={problem['correct_answer']}")
            
            results.append({
                'question_id': problem['question_id'],
                'predicted': answer_result['predicted_answer'],
                'correct': problem['correct_answer'],
                'is_correct': is_correct,
                'time': answer_result['response_time']
            })
        
        accuracy = correct_count / len(test_problems)
        print(f"\nğŸ¯ ãƒ†ã‚¹ãƒˆçµæœ: {correct_count}/{len(test_problems)} ({accuracy:.1%})")
        
        return True
        
    except Exception as e:
        print(f"âŒ å°‘æ•°å•é¡Œãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("="*60)
    print("ğŸ§ª ã‚·ãƒ³ãƒ—ãƒ«MMLUã‚¹ã‚³ã‚¢ãƒ©ãƒ¼ ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("="*60)
    
    # APIã‚­ãƒ¼ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return 1
    else:
        print("âœ… OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tests = [
        ("å˜ä¸€å•é¡Œãƒ†ã‚¹ãƒˆ", test_single_question),
        ("CSVèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ", test_csv_loading),
        ("å°‘æ•°å•é¡Œãƒ†ã‚¹ãƒˆ", test_few_questions)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*40}")
        print(f"å®Ÿè¡Œä¸­: {test_name}")
        print(f"{'='*40}")
        
        try:
            if test_func():
                print(f"âœ… {test_name} æˆåŠŸ")
                passed += 1
            else:
                print(f"âŒ {test_name} å¤±æ•—")
        except Exception as e:
            print(f"âŒ {test_name} ä¾‹å¤–: {e}")
    
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆçµæœ: {passed}/{total} æˆåŠŸ")
    print(f"{'='*60}")
    
    return 0 if passed == total else 1

if __name__ == "__main__":
    exit(main())